{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model 1 - LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8M_9KPB7-p7",
        "outputId": "4dfad1c1-c86e-4644-88b6-b3056b1bb1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8smHaYE5NjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import heapq\n",
        "import tweepy # https://github.com/tweepy/tweepy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import configparser\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, LSTM, Dropout, GRU, TimeDistributed, BatchNormalization\n",
        "from keras.layers import CuDNNLSTM \n",
        "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Handler = 'elonmusk'\n",
        "path = 'drive/MyDrive/Colab Notebooks/COE494_Project'"
      ],
      "metadata": {
        "id": "38CtxbJR8E3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def authenticate(path = 'drive/MyDrive/Colab Notebooks/COE494_Project/'):\n",
        "  # read config\n",
        "  config = configparser.ConfigParser()\n",
        "  config.read(path + 'config.ini')\n",
        "\n",
        "  api_key = str(config['twitter']['api_key'])\n",
        "  api_key_secret = str(config['twitter']['api_key_secret'])\n",
        "\n",
        "  access_token = str(config['twitter']['access_token'])\n",
        "  access_token_secret = str(config['twitter']['access_token_secret'])\n",
        "\n",
        "  # authenticate\n",
        "  auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "  return tweepy.API(auth, wait_on_rate_limit = True)"
      ],
      "metadata": {
        "id": "Xa0hXyXe76I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = authenticate()"
      ],
      "metadata": {
        "id": "WhMor-Av-oVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet text pre-processing\n",
        "def clean_tweet(tweet):\n",
        "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
        "    if type(tweet) == float:\n",
        "        return \"\"\n",
        "    temp = tweet.lower()\n",
        "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
        "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
        "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
        "    temp = re.sub(r'http\\S+', '', temp)\n",
        "    temp = re.sub('[()!?]', ' ', temp)\n",
        "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
        "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
        "    temp = temp.split()\n",
        "    temp = [w for w in temp if not w in stopwords]\n",
        "    temp = \" \".join(word for word in temp)\n",
        "    return temp"
      ],
      "metadata": {
        "id": "vqsKbwJLGq_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_tweets(handler):\n",
        "    # Twitter only allows access to a users most recent 3240 tweets with this method\n",
        "    print(f'Grabbing @{handler}\\'s Tweets')\n",
        "    #initialize a list to hold all the tweepy Tweets\n",
        "    all_tweets = []  \n",
        "    \n",
        "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
        "    new_tweets = api.user_timeline(screen_name = handler, count = 200, include_rts = False, tweet_mode = 'extended')\n",
        "    \n",
        "    # save most recent tweets\n",
        "    all_tweets.extend(new_tweets)\n",
        "    \n",
        "    # save the id of the oldest tweet less one\n",
        "    oldest = all_tweets[-1].id - 1\n",
        "    \n",
        "    # keep grabbing tweets until there are no tweets left to grab\n",
        "    while len(new_tweets) > 0:        \n",
        "        # all subsiquent requests use the max_id param to prevent duplicates\n",
        "        new_tweets = api.user_timeline(screen_name = handler, count=200, max_id = oldest, include_rts = False, tweet_mode = 'extended')\n",
        "        # save most recent tweets\n",
        "        all_tweets.extend(new_tweets)        \n",
        "        # update the id of the oldest tweet less one\n",
        "        oldest = all_tweets[-1].id - 1\n",
        "        \n",
        "    print(f\"{len(all_tweets)} tweets downloaded...\")    \n",
        "    # transform the tweepy tweets into a 2D array that will populate the csv \n",
        "    out_tweets = [[tweet.id_str, tweet.created_at, tweet.full_text] for tweet in all_tweets]\n",
        "    df = pd.DataFrame (out_tweets, columns = [\"id\", \"time\", \"tweet\"])\n",
        "    df.to_csv(path + '/data/' + handler+'.csv')\n",
        "    return df"
      ],
      "metadata": {
        "id": "glkVV-wN5UF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tweets = get_all_tweets(Handler)\n",
        "tweets = pd.read_csv(path + \"/data/elonmusk.csv\")\n",
        "cleaned_tweets = pd.DataFrame([clean_tweet(tweet) for tweet in tweets.tweet], columns = ['tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiqa6IyV5UIQ",
        "outputId": "58733c8d-8f3b-4e37-8bc6-2cb98f051f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2,4,9,14,16,17,19,22,24,25,26,31,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing null and empty rows \n",
        "cleaned_tweets.tweet.replace('', np.nan, inplace=True)\n",
        "cleaned_tweets.dropna(inplace = True)\n",
        "cleaned_tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_0rMIiyh5UKT",
        "outputId": "406603c6-9e5f-4233-f864-93002571295f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet\n",
              "0      please ignore prior tweets as that was someone...\n",
              "1                                                so true\n",
              "2      if you ever wanted know real truth about moon ...\n",
              "3      walked around neighborhood recently rebuilt wi...\n",
              "4      it was xmas so we brought presents kids at orp...\n",
              "...                                                  ...\n",
              "34870  reminds me when i hex edited ultima v get out ...\n",
              "34871                                    yay switzerland\n",
              "34872  there is no way be touch with voters when you ...\n",
              "34874                     let s make roaring 20 s happen\n",
              "34875                 great work by tesla team worldwide\n",
              "\n",
              "[33624 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba55ce89-8600-4427-9dba-59e22e26cf9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>please ignore prior tweets as that was someone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>if you ever wanted know real truth about moon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>walked around neighborhood recently rebuilt wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it was xmas so we brought presents kids at orp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34870</th>\n",
              "      <td>reminds me when i hex edited ultima v get out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34871</th>\n",
              "      <td>yay switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34872</th>\n",
              "      <td>there is no way be touch with voters when you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34874</th>\n",
              "      <td>let s make roaring 20 s happen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34875</th>\n",
              "      <td>great work by tesla team worldwide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33624 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba55ce89-8600-4427-9dba-59e22e26cf9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba55ce89-8600-4427-9dba-59e22e26cf9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba55ce89-8600-4427-9dba-59e22e26cf9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_tweets_text = ' '.join(cleaned_tweets[\"tweet\"])"
      ],
      "metadata": {
        "id": "ojhGb1aDCecH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "    return x\n",
        "\n",
        "def temperatureSample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
        "\n",
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "\n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "            return completion\n",
        "\n",
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n"
      ],
      "metadata": {
        "id": "V-VB4AC_0WLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = raw_tweets_text\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(f'unique chars: {len(chars)}')\n",
        "\n",
        "SEQUENCE_LENGTH = 80\n",
        "step = 4\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
        "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
        "print(f'num training examples: {len(sentences)}')\n",
        "\n",
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"y.shape:\", y.shape)"
      ],
      "metadata": {
        "id": "EWvnfg5Z1Q56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018e22bb-704b-4da7-dc85-e650e11c47ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 2241073\n",
            "unique chars: 37\n",
            "num training examples: 560249\n",
            "X.shape: (560249, 80, 37)\n",
            "y.shape: (560249, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(CuDNNLSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars) * 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars) * 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr = 0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIx7KBGCRgST",
        "outputId": "13851726-464b-4200-d4b6-18db1c76bdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RU8Tb5xRo5R",
        "outputId": "0c95a460-7cdb-43fd-a1ae-09fd97a815ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 185)               165760    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 185)              740       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 185)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 74)                13764     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 74)               296       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 74)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 74)                5550      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 74)               296       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 74)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                2775      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 189,181\n",
            "Trainable params: 188,515\n",
            "Non-trainable params: 666\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, validation_split = 0.05, batch_size = 124, epochs = 50, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPOTQinYoTDg",
        "outputId": "f1e85ad9-6476-4d16-8f86-fc3e5f2d063e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4293/4293 [==============================] - 57s 13ms/step - loss: 2.0829 - accuracy: 0.3749 - val_loss: 2.1086 - val_accuracy: 0.3787\n",
            "Epoch 2/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.8246 - accuracy: 0.4451 - val_loss: 1.8470 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.6883 - accuracy: 0.4844 - val_loss: 1.7000 - val_accuracy: 0.4828\n",
            "Epoch 4/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.5923 - accuracy: 0.5115 - val_loss: 1.6349 - val_accuracy: 0.4997\n",
            "Epoch 5/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.5215 - accuracy: 0.5314 - val_loss: 1.5949 - val_accuracy: 0.5128\n",
            "Epoch 6/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.4657 - accuracy: 0.5474 - val_loss: 1.5805 - val_accuracy: 0.5199\n",
            "Epoch 7/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.4184 - accuracy: 0.5621 - val_loss: 1.5697 - val_accuracy: 0.5261\n",
            "Epoch 8/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.3767 - accuracy: 0.5743 - val_loss: 1.5695 - val_accuracy: 0.5267\n",
            "Epoch 9/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.3385 - accuracy: 0.5868 - val_loss: 1.5720 - val_accuracy: 0.5274\n",
            "Epoch 10/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.3034 - accuracy: 0.5978 - val_loss: 1.5788 - val_accuracy: 0.5271\n",
            "Epoch 11/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.2709 - accuracy: 0.6081 - val_loss: 1.5927 - val_accuracy: 0.5251\n",
            "Epoch 12/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.2403 - accuracy: 0.6189 - val_loss: 1.6136 - val_accuracy: 0.5235\n",
            "Epoch 13/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.2115 - accuracy: 0.6290 - val_loss: 1.6371 - val_accuracy: 0.5225\n",
            "Epoch 14/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.1851 - accuracy: 0.6381 - val_loss: 1.6659 - val_accuracy: 0.5196\n",
            "Epoch 15/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.1608 - accuracy: 0.6466 - val_loss: 1.6845 - val_accuracy: 0.5190\n",
            "Epoch 16/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.1388 - accuracy: 0.6540 - val_loss: 1.7052 - val_accuracy: 0.5184\n",
            "Epoch 17/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.1190 - accuracy: 0.6606 - val_loss: 1.7266 - val_accuracy: 0.5141\n",
            "Epoch 18/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.1019 - accuracy: 0.6661 - val_loss: 1.7407 - val_accuracy: 0.5146\n",
            "Epoch 19/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0864 - accuracy: 0.6707 - val_loss: 1.7578 - val_accuracy: 0.5110\n",
            "Epoch 20/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0731 - accuracy: 0.6741 - val_loss: 1.7768 - val_accuracy: 0.5109\n",
            "Epoch 21/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.0610 - accuracy: 0.6780 - val_loss: 1.7885 - val_accuracy: 0.5104\n",
            "Epoch 22/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0505 - accuracy: 0.6816 - val_loss: 1.8038 - val_accuracy: 0.5109\n",
            "Epoch 23/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0399 - accuracy: 0.6844 - val_loss: 1.8128 - val_accuracy: 0.5099\n",
            "Epoch 24/50\n",
            "4293/4293 [==============================] - 56s 13ms/step - loss: 1.0314 - accuracy: 0.6874 - val_loss: 1.8284 - val_accuracy: 0.5098\n",
            "Epoch 25/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0226 - accuracy: 0.6894 - val_loss: 1.8300 - val_accuracy: 0.5101\n",
            "Epoch 26/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0145 - accuracy: 0.6916 - val_loss: 1.8401 - val_accuracy: 0.5097\n",
            "Epoch 27/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 1.0078 - accuracy: 0.6938 - val_loss: 1.8518 - val_accuracy: 0.5083\n",
            "Epoch 28/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 1.0013 - accuracy: 0.6959 - val_loss: 1.8599 - val_accuracy: 0.5070\n",
            "Epoch 29/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9942 - accuracy: 0.6974 - val_loss: 1.8769 - val_accuracy: 0.5064\n",
            "Epoch 30/50\n",
            "4293/4293 [==============================] - 56s 13ms/step - loss: 0.9895 - accuracy: 0.6985 - val_loss: 1.8833 - val_accuracy: 0.5058\n",
            "Epoch 31/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9834 - accuracy: 0.7001 - val_loss: 1.8971 - val_accuracy: 0.5044\n",
            "Epoch 32/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9783 - accuracy: 0.7021 - val_loss: 1.9139 - val_accuracy: 0.5055\n",
            "Epoch 33/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9727 - accuracy: 0.7036 - val_loss: 1.9112 - val_accuracy: 0.5045\n",
            "Epoch 34/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9676 - accuracy: 0.7049 - val_loss: 1.9253 - val_accuracy: 0.5041\n",
            "Epoch 35/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9629 - accuracy: 0.7068 - val_loss: 1.9324 - val_accuracy: 0.5038\n",
            "Epoch 36/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9589 - accuracy: 0.7078 - val_loss: 1.9361 - val_accuracy: 0.5038\n",
            "Epoch 37/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9538 - accuracy: 0.7092 - val_loss: 1.9497 - val_accuracy: 0.5020\n",
            "Epoch 38/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9497 - accuracy: 0.7102 - val_loss: 1.9499 - val_accuracy: 0.5039\n",
            "Epoch 39/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9468 - accuracy: 0.7115 - val_loss: 1.9606 - val_accuracy: 0.5034\n",
            "Epoch 40/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9426 - accuracy: 0.7126 - val_loss: 1.9633 - val_accuracy: 0.5033\n",
            "Epoch 41/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9389 - accuracy: 0.7139 - val_loss: 1.9871 - val_accuracy: 0.5016\n",
            "Epoch 42/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9365 - accuracy: 0.7145 - val_loss: 1.9846 - val_accuracy: 0.5023\n",
            "Epoch 43/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9323 - accuracy: 0.7161 - val_loss: 1.9802 - val_accuracy: 0.5018\n",
            "Epoch 44/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9290 - accuracy: 0.7166 - val_loss: 1.9935 - val_accuracy: 0.5022\n",
            "Epoch 45/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9270 - accuracy: 0.7175 - val_loss: 1.9939 - val_accuracy: 0.5012\n",
            "Epoch 46/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9232 - accuracy: 0.7189 - val_loss: 1.9990 - val_accuracy: 0.5016\n",
            "Epoch 47/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9203 - accuracy: 0.7196 - val_loss: 2.0151 - val_accuracy: 0.5009\n",
            "Epoch 48/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9177 - accuracy: 0.7201 - val_loss: 2.0213 - val_accuracy: 0.5007\n",
            "Epoch 49/50\n",
            "4293/4293 [==============================] - 55s 13ms/step - loss: 0.9148 - accuracy: 0.7208 - val_loss: 2.0090 - val_accuracy: 0.4999\n",
            "Epoch 50/50\n",
            "4293/4293 [==============================] - 54s 13ms/step - loss: 0.9128 - accuracy: 0.7212 - val_loss: 2.0275 - val_accuracy: 0.4988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab40074450>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(path + \"/models/3_LSTM\")"
      ],
      "metadata": {
        "id": "GTKexSImrZ21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(path + \"/models/3_LSTM\")"
      ],
      "metadata": {
        "id": "miXDj42yro_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genSentence(text, words = 2):\n",
        "    textOG = text\n",
        "    text = text.lower()\n",
        "    while len(text) < SEQUENCE_LENGTH:\n",
        "        text = ' ' + text\n",
        "    text = text[-SEQUENCE_LENGTH:]\n",
        "    for i in range(words):\n",
        "        text = text[-SEQUENCE_LENGTH:]\n",
        "        pred = predict_completions(text, 1)[0]\n",
        "        text = text + pred\n",
        "        textOG = textOG + pred\n",
        "        pass\n",
        "    return textOG"
      ],
      "metadata": {
        "id": "b2zn8M0prLDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Tweets starting from the given words \n",
        "# Generates random length from the training set\n",
        "\n",
        "## Random Number of words and seed word may be generated, however we are choosing\n",
        "## constant values for comparison sake\n",
        "### N_WORDS = 0\n",
        "### while N_WORDS < 10:\n",
        "###   N_WORDS = len(cleaned_tweets.sample().tweet.item())\n",
        "\n",
        "### seed = cleaned_tweets.sample().tweet.item().split()[0]\n",
        "\n",
        "seed = 'Roadster'\n",
        "N_WORDS = 10\n",
        "print(genSentence(seed, N_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxRfAHQg0c-g",
        "outputId": "ce7eb7af-2694-40c6-9cdc-71c345aafc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roadster this is also with energy probably preking i should be \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 'Finally'\n",
        "N_WORDS = 10\n",
        "print(genSentence(seed, N_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6KoQWalq8Ox",
        "outputId": "db338268-f58a-4b65-c1bd-72125a320a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finally all good this is also all about will be fine \n"
          ]
        }
      ]
    }
  ]
}