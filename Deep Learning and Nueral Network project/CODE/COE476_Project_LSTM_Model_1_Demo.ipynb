{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COE476_Project_LSTM_Model_1_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Initializing Variables and Importing Libraries"
      ],
      "metadata": {
        "id": "-NbsJRlm8WIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8M_9KPB7-p7",
        "outputId": "a73309cd-8c2a-4e5d-895b-59a9147ceb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8smHaYE5NjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import heapq\n",
        "import tweepy # https://github.com/tweepy/tweepy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import configparser\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, LSTM, Dropout, GRU, TimeDistributed, BatchNormalization\n",
        "from keras.layers import CuDNNLSTM \n",
        "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# twitter handler of user to fetch data for\n",
        "Handler = \"elonmusk\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "i5VoOaN26gBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing variables\n",
        "path    = 'drive/MyDrive/Colab Notebooks/COE494_Project'\n",
        "Model   =  {\n",
        "      'Type': 'LSTM',\n",
        "      'seed' : {}\n",
        "    }"
      ],
      "metadata": {
        "id": "38CtxbJR8E3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing and Grabbing the data"
      ],
      "metadata": {
        "id": "go_Ke_1y8erZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Twitter API authentication \n",
        "def authenticate(path = 'drive/MyDrive/Colab Notebooks/COE494_Project/'):\n",
        "  # read config\n",
        "  config = configparser.ConfigParser()\n",
        "  config.read(path + 'config.ini')\n",
        "\n",
        "  api_key = str(config['twitter']['api_key'])\n",
        "  api_key_secret = str(config['twitter']['api_key_secret'])\n",
        "\n",
        "  access_token = str(config['twitter']['access_token'])\n",
        "  access_token_secret = str(config['twitter']['access_token_secret'])\n",
        "\n",
        "  # authenticate\n",
        "  auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "  return tweepy.API(auth, wait_on_rate_limit = True)"
      ],
      "metadata": {
        "id": "Xa0hXyXe76I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = authenticate()"
      ],
      "metadata": {
        "id": "WhMor-Av-oVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch latest user tweets\n",
        "def get_all_tweets(handler):\n",
        "    # Twitter only allows access to a users most recent 3240 tweets with this method\n",
        "    print(f'Grabbing @{handler}\\'s Tweets')\n",
        "    #initialize a list to hold all the tweepy Tweets\n",
        "    all_tweets = []  \n",
        "    \n",
        "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
        "    new_tweets = api.user_timeline(screen_name = handler, count = 200, include_rts = False, tweet_mode = 'extended')\n",
        "    \n",
        "    # save most recent tweets\n",
        "    all_tweets.extend(new_tweets)\n",
        "    \n",
        "    # save the id of the oldest tweet less one\n",
        "    oldest = all_tweets[-1].id - 1\n",
        "    \n",
        "    # keep grabbing tweets until there are no tweets left to grab\n",
        "    while len(new_tweets) > 0:        \n",
        "        # all subsiquent requests use the max_id param to prevent duplicates\n",
        "        new_tweets = api.user_timeline(screen_name = handler, count=200, max_id = oldest, include_rts = False, tweet_mode = 'extended')\n",
        "        # save most recent tweets\n",
        "        all_tweets.extend(new_tweets)        \n",
        "        # update the id of the oldest tweet less one\n",
        "        oldest = all_tweets[-1].id - 1\n",
        "        \n",
        "    print(f\"{len(all_tweets)} tweets downloaded...\")    \n",
        "    # transform the tweepy tweets into a 2D array that will populate the csv \n",
        "    out_tweets = [[tweet.id_str, tweet.created_at, tweet.full_text] for tweet in all_tweets]\n",
        "    df = pd.DataFrame (out_tweets, columns = [\"id\", \"time\", \"tweet\"])\n",
        "    df.to_csv(path + '/data/' + handler+'.csv')\n",
        "    return df"
      ],
      "metadata": {
        "id": "glkVV-wN5UF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching, reading of tweets\n",
        "# tweets = get_all_tweets(Handler)\n",
        "tweets = pd.read_csv(path + \"/data/\" + Handler + \".csv\")\n",
        "print('Tweets Fetched -')\n",
        "tweets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "hiqa6IyV5UIQ",
        "outputId": "5e2fd630-60a5-4778-f0ad-cb8456696717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweets Fetched -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2,4,9,14,16,17,19,22,24,25,26,31,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id  conversation_id       created_at              date timezone  \\\n",
              "0  1.543473e+10     1.543473e+10  1280000000000.0  04/06/2010 18:31        0   \n",
              "1  1.520000e+17     1.520000e+17  1330000000000.0  28/12/2011 22:27        0   \n",
              "2  1.520000e+17     1.520000e+17  1330000000000.0  27/12/2011 23:38        0   \n",
              "3  1.510000e+17     1.510000e+17  1320000000000.0  26/12/2011 16:29        0   \n",
              "4  1.510000e+17     1.510000e+17  1320000000000.0  26/12/2011 16:23        0   \n",
              "\n",
              "   place                                              tweet language hashtags  \\\n",
              "0    NaN  Please ignore prior tweets, as that was someon...       en       []   \n",
              "1    NaN                               @TheOnion So true :)       en       []   \n",
              "2    NaN  If you ever wanted to know the *real* truth ab...       en       []   \n",
              "3    NaN  Walked around a neighborhood recently rebuilt ...       en       []   \n",
              "4    NaN  It was Xmas, so we brought presents for the ki...       en       []   \n",
              "\n",
              "  cashtags  ...  geo  source user_rt_id user_rt retweet_id  reply_to  \\\n",
              "0       []  ...  NaN     NaN        NaN     NaN        NaN        []   \n",
              "1       []  ...  NaN     NaN        NaN     NaN        NaN        []   \n",
              "2       []  ...  NaN     NaN        NaN     NaN        NaN        []   \n",
              "3       []  ...  NaN     NaN        NaN     NaN        NaN        []   \n",
              "4       []  ...  NaN     NaN        NaN     NaN        NaN        []   \n",
              "\n",
              "  retweet_date translate trans_src trans_dest  \n",
              "0          NaN       NaN       NaN        NaN  \n",
              "1          NaN       NaN       NaN        NaN  \n",
              "2          NaN       NaN       NaN        NaN  \n",
              "3          NaN       NaN       NaN        NaN  \n",
              "4          NaN       NaN       NaN        NaN  \n",
              "\n",
              "[5 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a39370d7-80ec-4d19-9ec9-3ecf0761874f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>timezone</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>...</th>\n",
              "      <th>geo</th>\n",
              "      <th>source</th>\n",
              "      <th>user_rt_id</th>\n",
              "      <th>user_rt</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>retweet_date</th>\n",
              "      <th>translate</th>\n",
              "      <th>trans_src</th>\n",
              "      <th>trans_dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.543473e+10</td>\n",
              "      <td>1.543473e+10</td>\n",
              "      <td>1280000000000.0</td>\n",
              "      <td>04/06/2010 18:31</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Please ignore prior tweets, as that was someon...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.520000e+17</td>\n",
              "      <td>1.520000e+17</td>\n",
              "      <td>1330000000000.0</td>\n",
              "      <td>28/12/2011 22:27</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@TheOnion So true :)</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.520000e+17</td>\n",
              "      <td>1.520000e+17</td>\n",
              "      <td>1330000000000.0</td>\n",
              "      <td>27/12/2011 23:38</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If you ever wanted to know the *real* truth ab...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.510000e+17</td>\n",
              "      <td>1.510000e+17</td>\n",
              "      <td>1320000000000.0</td>\n",
              "      <td>26/12/2011 16:29</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.510000e+17</td>\n",
              "      <td>1.510000e+17</td>\n",
              "      <td>1320000000000.0</td>\n",
              "      <td>26/12/2011 16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It was Xmas, so we brought presents for the ki...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a39370d7-80ec-4d19-9ec9-3ecf0761874f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a39370d7-80ec-4d19-9ec9-3ecf0761874f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a39370d7-80ec-4d19-9ec9-3ecf0761874f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cleaning the data"
      ],
      "metadata": {
        "id": "6nS8SrgX8kOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet text pre-processing\n",
        "def clean_tweet(tweet):\n",
        "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\", \"amp\"]\n",
        "    if type(tweet) == float:\n",
        "        return \"\"\n",
        "    temp = tweet.lower()\n",
        "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
        "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
        "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
        "    temp = re.sub(r'http\\S+', '', temp)\n",
        "    temp = re.sub('[()!?]', ' ', temp)\n",
        "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
        "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
        "    temp = temp.split()\n",
        "    temp = [w for w in temp if not w in stopwords]\n",
        "    temp = \" \".join(word for word in temp)\n",
        "    return temp"
      ],
      "metadata": {
        "id": "lX9GJm518rs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning tweets\n",
        "cleaned_tweets = pd.DataFrame([clean_tweet(tweet) for tweet in tweets.tweet], columns = ['tweet'])\n",
        "\n",
        "# Removing null and empty rows after cleaning\n",
        "cleaned_tweets.tweet.replace('', np.nan, inplace=True)\n",
        "cleaned_tweets.dropna(inplace = True)\n",
        "\n",
        "print('Tweets Cleaned -')\n",
        "cleaned_tweets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "_0rMIiyh5UKT",
        "outputId": "ef67411d-654d-468e-8a33-a6f126cb41f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweets Cleaned -\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet\n",
              "0  please ignore prior tweets as that was someone...\n",
              "1                                            so true\n",
              "2  if you ever wanted know real truth about moon ...\n",
              "3  walked around neighborhood recently rebuilt wi...\n",
              "4  it was xmas so we brought presents kids at orp..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51f6dc56-3634-459f-8ff7-d77b66792fcb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>please ignore prior tweets as that was someone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>if you ever wanted know real truth about moon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>walked around neighborhood recently rebuilt wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it was xmas so we brought presents kids at orp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51f6dc56-3634-459f-8ff7-d77b66792fcb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51f6dc56-3634-459f-8ff7-d77b66792fcb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51f6dc56-3634-459f-8ff7-d77b66792fcb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Feature Engineering"
      ],
      "metadata": {
        "id": "RhzV24Iu87uF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening the cleaned tweets data from a dataframe to a string"
      ],
      "metadata": {
        "id": "nN4agCwz8u2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_tweets_text = ' '.join(cleaned_tweets[\"tweet\"])"
      ],
      "metadata": {
        "id": "ojhGb1aDCecH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization, segmentation and text processing functions \n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "    return x\n",
        "\n",
        "def temperatureSample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
        "\n",
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "\n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "            return completion\n",
        "\n",
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n"
      ],
      "metadata": {
        "id": "V-VB4AC_0WLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = raw_tweets_text\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "# initializing vocab and translators\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(f'unique chars: {len(chars)}')\n",
        "\n",
        "# initializing important parameters\n",
        "SEQUENCE_LENGTH = 80\n",
        "step = 4\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "# segmenting the data\n",
        "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
        "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
        "print(f'num training examples: {len(sentences)}')\n",
        "\n",
        "# Vectorization and initializing zero arrays for one hot encoding\n",
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "\n",
        "# encoding the data\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"y.shape:\", y.shape)"
      ],
      "metadata": {
        "id": "EWvnfg5Z1Q56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f930d29a-7b70-423e-999c-3fb3d9f70acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 2222261\n",
            "unique chars: 37\n",
            "num training examples: 555546\n",
            "X.shape: (555546, 80, 37)\n",
            "y.shape: (555546, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Building"
      ],
      "metadata": {
        "id": "4q_Istkx8P-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(CuDNNLSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars) * 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars) * 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr = 0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oIx7KBGCRgST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RU8Tb5xRo5R",
        "outputId": "ca4aa2e6-9311-44ce-b0ad-80dac2579222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 185)               165760    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 185)              740       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 185)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 74)                13764     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 74)               296       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 74)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 74)                5550      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 74)               296       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 74)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                2775      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 189,181\n",
            "Trainable params: 188,515\n",
            "Non-trainable params: 666\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, validation_split = 0.05, batch_size = 124, epochs = 50, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPOTQinYoTDg",
        "outputId": "23b5e5ed-6a48-43bf-ff7e-77bb6d6d9750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4257/4257 [==============================] - 64s 13ms/step - loss: 2.0974 - accuracy: 0.3700 - val_loss: 2.1691 - val_accuracy: 0.3421\n",
            "Epoch 2/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.8266 - accuracy: 0.4432 - val_loss: 1.8652 - val_accuracy: 0.4304\n",
            "Epoch 3/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.6874 - accuracy: 0.4838 - val_loss: 1.7055 - val_accuracy: 0.4829\n",
            "Epoch 4/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.5922 - accuracy: 0.5100 - val_loss: 1.6421 - val_accuracy: 0.4915\n",
            "Epoch 5/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.5247 - accuracy: 0.5283 - val_loss: 1.6030 - val_accuracy: 0.5111\n",
            "Epoch 6/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.4727 - accuracy: 0.5428 - val_loss: 1.5918 - val_accuracy: 0.5114\n",
            "Epoch 7/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.4309 - accuracy: 0.5546 - val_loss: 1.5553 - val_accuracy: 0.5276\n",
            "Epoch 8/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.3936 - accuracy: 0.5651 - val_loss: 1.5473 - val_accuracy: 0.5262\n",
            "Epoch 9/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.3608 - accuracy: 0.5746 - val_loss: 1.5602 - val_accuracy: 0.5263\n",
            "Epoch 10/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.3314 - accuracy: 0.5834 - val_loss: 1.5421 - val_accuracy: 0.5323\n",
            "Epoch 11/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.3025 - accuracy: 0.5922 - val_loss: 1.5451 - val_accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.2774 - accuracy: 0.5996 - val_loss: 1.5735 - val_accuracy: 0.5330\n",
            "Epoch 13/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.2519 - accuracy: 0.6082 - val_loss: 1.5804 - val_accuracy: 0.5318\n",
            "Epoch 14/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.2291 - accuracy: 0.6153 - val_loss: 1.5802 - val_accuracy: 0.5302\n",
            "Epoch 15/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.2065 - accuracy: 0.6225 - val_loss: 1.6074 - val_accuracy: 0.5303\n",
            "Epoch 16/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.1854 - accuracy: 0.6295 - val_loss: 1.6234 - val_accuracy: 0.5323\n",
            "Epoch 17/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.1652 - accuracy: 0.6361 - val_loss: 1.6348 - val_accuracy: 0.5270\n",
            "Epoch 18/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.1460 - accuracy: 0.6424 - val_loss: 1.6662 - val_accuracy: 0.5264\n",
            "Epoch 19/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.1301 - accuracy: 0.6477 - val_loss: 1.6711 - val_accuracy: 0.5274\n",
            "Epoch 20/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.1115 - accuracy: 0.6540 - val_loss: 1.6910 - val_accuracy: 0.5216\n",
            "Epoch 21/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.0964 - accuracy: 0.6590 - val_loss: 1.7152 - val_accuracy: 0.5243\n",
            "Epoch 22/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0818 - accuracy: 0.6638 - val_loss: 1.7258 - val_accuracy: 0.5216\n",
            "Epoch 23/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0683 - accuracy: 0.6684 - val_loss: 1.7482 - val_accuracy: 0.5200\n",
            "Epoch 24/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0545 - accuracy: 0.6727 - val_loss: 1.7655 - val_accuracy: 0.5176\n",
            "Epoch 25/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0428 - accuracy: 0.6766 - val_loss: 1.7841 - val_accuracy: 0.5152\n",
            "Epoch 26/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0306 - accuracy: 0.6808 - val_loss: 1.8100 - val_accuracy: 0.5139\n",
            "Epoch 27/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0210 - accuracy: 0.6843 - val_loss: 1.8001 - val_accuracy: 0.5181\n",
            "Epoch 28/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 1.0100 - accuracy: 0.6877 - val_loss: 1.8376 - val_accuracy: 0.5114\n",
            "Epoch 29/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 1.0012 - accuracy: 0.6897 - val_loss: 1.8398 - val_accuracy: 0.5120\n",
            "Epoch 30/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9941 - accuracy: 0.6923 - val_loss: 1.8567 - val_accuracy: 0.5108\n",
            "Epoch 31/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9852 - accuracy: 0.6958 - val_loss: 1.8716 - val_accuracy: 0.5111\n",
            "Epoch 32/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9776 - accuracy: 0.6978 - val_loss: 1.8778 - val_accuracy: 0.5093\n",
            "Epoch 33/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9713 - accuracy: 0.6998 - val_loss: 1.8922 - val_accuracy: 0.5069\n",
            "Epoch 34/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9644 - accuracy: 0.7018 - val_loss: 1.9025 - val_accuracy: 0.5078\n",
            "Epoch 35/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9580 - accuracy: 0.7036 - val_loss: 1.8966 - val_accuracy: 0.5050\n",
            "Epoch 36/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9529 - accuracy: 0.7058 - val_loss: 1.9178 - val_accuracy: 0.5054\n",
            "Epoch 37/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9479 - accuracy: 0.7070 - val_loss: 1.9315 - val_accuracy: 0.5052\n",
            "Epoch 38/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9422 - accuracy: 0.7089 - val_loss: 1.9259 - val_accuracy: 0.5080\n",
            "Epoch 39/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9362 - accuracy: 0.7104 - val_loss: 1.9377 - val_accuracy: 0.5087\n",
            "Epoch 40/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9327 - accuracy: 0.7118 - val_loss: 1.9453 - val_accuracy: 0.5039\n",
            "Epoch 41/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9275 - accuracy: 0.7130 - val_loss: 1.9668 - val_accuracy: 0.5031\n",
            "Epoch 42/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9233 - accuracy: 0.7145 - val_loss: 1.9835 - val_accuracy: 0.5041\n",
            "Epoch 43/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9196 - accuracy: 0.7162 - val_loss: 1.9778 - val_accuracy: 0.5078\n",
            "Epoch 44/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9146 - accuracy: 0.7176 - val_loss: 1.9772 - val_accuracy: 0.5075\n",
            "Epoch 45/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9104 - accuracy: 0.7184 - val_loss: 1.9952 - val_accuracy: 0.5051\n",
            "Epoch 46/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9074 - accuracy: 0.7193 - val_loss: 1.9953 - val_accuracy: 0.5040\n",
            "Epoch 47/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.9033 - accuracy: 0.7208 - val_loss: 1.9926 - val_accuracy: 0.5053\n",
            "Epoch 48/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.9014 - accuracy: 0.7214 - val_loss: 2.0128 - val_accuracy: 0.5055\n",
            "Epoch 49/50\n",
            "4257/4257 [==============================] - 55s 13ms/step - loss: 0.8977 - accuracy: 0.7226 - val_loss: 2.0011 - val_accuracy: 0.5020\n",
            "Epoch 50/50\n",
            "4257/4257 [==============================] - 54s 13ms/step - loss: 0.8951 - accuracy: 0.7228 - val_loss: 1.9945 - val_accuracy: 0.5051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f317058e0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tweet Prediction and Text Generator"
      ],
      "metadata": {
        "id": "84R96KG_9VXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def genSentence(text, words = 2):\n",
        "    textOG = text\n",
        "    text = text.lower()\n",
        "    while len(text) < SEQUENCE_LENGTH:\n",
        "        text = ' ' + text\n",
        "    text = text[-SEQUENCE_LENGTH:]\n",
        "    for i in range(words):\n",
        "        text = text[-SEQUENCE_LENGTH:]\n",
        "        pred = predict_completions(text, 1)[0]\n",
        "        text = text + pred\n",
        "        textOG = textOG + pred\n",
        "        pass\n",
        "    return textOG"
      ],
      "metadata": {
        "id": "b2zn8M0prLDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output 1, using the first seed"
      ],
      "metadata": {
        "id": "fOz8RhQ79cvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Tweets starting from the given words \n",
        "# Generates random length from the training set\n",
        "\n",
        "# Random Number of words and seed word may be generated, however we are choosing\n",
        "# constant values for comparison sake\n",
        "N_WORDS = 0\n",
        "while N_WORDS < 10 or N_WORDS > 50:\n",
        "  N_WORDS = len(cleaned_tweets.sample().tweet.item())\n",
        "\n",
        "seed_1 = cleaned_tweets.sample().tweet.item().split()[0]\n",
        "Model['seed'][seed_1] = genSentence(seed_1, N_WORDS)\n",
        "\n",
        "print('Prompt:', seed_1)\n",
        "print('Prediction:', Model['seed'][seed_1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxRfAHQg0c-g",
        "outputId": "89ffb931-370e-4599-8c9a-bd6d3ee5692a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: will\n",
            "Prediction: will probably autocuthered that we week publication is that it s not that it s indeed eserted obv approvals performance people viever i superchargers come point i lived ever systemicb \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output 2, using the second seed"
      ],
      "metadata": {
        "id": "KynJJCgk9f6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Tweets starting from the given words \n",
        "# Generates random length from the training set\n",
        "\n",
        "# Random Number of words and seed word may be generated, however we are choosing\n",
        "# constant values for comparison sake\n",
        "N_WORDS = 0\n",
        "while N_WORDS < 10 or N_WORDS > 50:\n",
        "  N_WORDS = len(cleaned_tweets.sample().tweet.item())\n",
        "\n",
        "seed_2 = cleaned_tweets.sample().tweet.item().split()[0]\n",
        "Model['seed'][seed_2] = genSentence(seed_2, N_WORDS)\n",
        "\n",
        "print('Prompt:', seed_2)\n",
        "print('Prediction:', Model['seed'][seed_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6KoQWalq8Ox",
        "outputId": "54afc128-a762-4829-e227-030d5a93d932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: going\n",
            "Prediction: going regularmeahopens should be super heavy so they will be super card that i do put this is that it s not that it s indeed eserted obv approvals performance people viever i superchargers come point i lived ever systemicb story that was easy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Model evaluation"
      ],
      "metadata": {
        "id": "TvkdY_HB-uFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from nltk.translate import bleu_score as bleu"
      ],
      "metadata": {
        "id": "0GlUorOe-tuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gens  = [gen for gen in list(Model['seed'].values())]\n",
        "# transforming the training data/referencing tweets into appropriate format\n",
        "reference_tweets = [sentence.split() for sentence in cleaned_tweets[\"tweet\"].tolist()]"
      ],
      "metadata": {
        "id": "6zLEwLzH_AVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed scores\n",
        "bleu_scors = [round(bleu.sentence_bleu(reference_tweets, tweet.split(), smoothing_function = bleu.SmoothingFunction().method4), 2) for tweet in model_gens]\n",
        "bleu_avg   = sum(bleu_scors) / len(bleu_scors)"
      ],
      "metadata": {
        "id": "963NvpR5_N_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = ['seed', Model['Type']], [seed_1, bleu_scors[0]], [seed_2, bleu_scors[1]], ['average scores', bleu_avg]\n",
        "tab = PrettyTable(table[0])\n",
        "tab.add_rows(table[1:])\n",
        "print(tab.get_string(title=\"BLUE Evaluation Scores\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjVuDovsAk5I",
        "outputId": "129157d9-fece-4c46-f955-0f5431443ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|  BLUE Evaluation Scores  |\n",
            "+------------------+-------+\n",
            "|       seed       |  LSTM |\n",
            "+------------------+-------+\n",
            "|       will       |  0.26 |\n",
            "|      going       |  0.26 |\n",
            "|  average scores  |  0.26 |\n",
            "+------------------+-------+\n"
          ]
        }
      ]
    }
  ]
}