{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of convolutional_neural_network.ipynb","provenance":[{"file_id":"1Y-a4g98w93GHswXLRLoiogvMYNPgzPE9","timestamp":1595089780447}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu","colab_type":"text"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60","colab_type":"text"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"omzt4Q7SwxgY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595091481370,"user_tz":-240,"elapsed":2295,"user":{"displayName":"mahmoud kharoof","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx1JGdWwdkYuAeerh_1bne3eE6XiWE4UkckTU3IQ=s64","userId":"04175753233013773418"}},"outputId":"aacc4552-f8e3-415f-8e7b-536716f3605d"},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vn--Bv3byHkF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595091482594,"user_tz":-240,"elapsed":642,"user":{"displayName":"mahmoud kharoof","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx1JGdWwdkYuAeerh_1bne3eE6XiWE4UkckTU3IQ=s64","userId":"04175753233013773418"}},"outputId":"4bb83471-2b2d-4072-a402-691e6f46fcb1"},"source":["tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'2.2.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE","colab_type":"text"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG","colab_type":"text"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"8AMUIYEXy5ub","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(\n","        rescale=1./255, # we rescaling each pexil to be between 1 and 0\n","        shear_range=0.2, \n","        zoom_range=0.2,\n","        horizontal_flip=True) #here we transforming the image so we make the CNN more flexibile to new images\n","\n","training_set = train_datagen.flow_from_directory(\n","        'dataset/training_set', # the directory where the images are\n","        target_size=(64, 64), # the final size of the images when they are fed to the CNN \n","        batch_size=32, # The number of images per batch\n","        class_mode='binary') # the output either 1 or 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys","colab_type":"text"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"id":"d8E1ETbO15eH","colab_type":"code","colab":{}},"source":["test_datagen = ImageDataGenerator(rescale=1./255) # here we are not transformin the images becuase they are new images that we want to predict their content\n","test_set = test_datagen.flow_from_directory(\n","        'data/test_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B","colab_type":"text"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX","colab_type":"text"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"ucgX32_T2pTl","colab_type":"code","colab":{}},"source":["cnn = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF","colab_type":"text"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"id":"cyJs7Eoe3RXW","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, # the filters variable express the number of Feature detectors that we want to have\n","                               kernel_size=3, # the size of the feature detector matrix here it is 3x3 which is always going to be squared\n","                               activation='relu', # The activation function for this layer is the rectifier function to get rid of the linearity\n","                               input_shape = [64, 64, 3] # the dimension of the input image which is 64x64 pixel and it is colored that is why we put 3 \n","                               )) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ","colab_type":"text"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"id":"p1R7lCn15EUx","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size = (2,2) # The size of the matrix that we pool to find the max of 4 adjacent elements\n","                                  , strides = 2 # The number of columns that we want to shift or slide at each pool\n","                                  ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU","colab_type":"text"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"wJLDDHJS6DTb","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, # the filters variable express the number of Feature detectors that we want to have\n","                               kernel_size=3, # the size of the feature detector matrix here it is 3x3 which is always going to be squared\n","                               activation='relu', # The activation function for this layer is the rectifier function to get rid of the linearity\n","                                )) \n","cnn.add(tf.keras.layers.MaxPool2D(pool_size = (2,2) # The size of the matrix that we pool to find the max of 4 adjacent elements\n","                                  , strides = 2 # The number of columns that we want to shift or slide at each pool\n","                                  ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk","colab_type":"text"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"9fgPx-PK6OBP","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v","colab_type":"text"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"XmPLp2HF6c4R","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units=128,\n","                              activation = 'relu',))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na","colab_type":"text"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"id":"jZ2NxqGY7tIP","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units=1, \n","                              activation = 'sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl","colab_type":"text"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i","colab_type":"text"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"TTfPHNie7y74","colab_type":"code","colab":{}},"source":["cnn.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h","colab_type":"text"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"id":"SAE6pvKk8gbB","colab_type":"code","colab":{}},"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z","colab_type":"text"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"id":"zMEn9_Aw9fWb","colab_type":"code","colab":{}},"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a60Kh7UxAezo","colab_type":"code","colab":{}},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}